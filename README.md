# group_loss: Hierarchical Structured Regularization

**group_loss** — механизм иерархической регуляризации для нейронных сетей, позволяющий применять **структурированные штрафы** (L1/L2) к группам параметров модели в соответствии с их архитектурной иерархией. Реализует идею «групповой разреженности», где параметры регулируются не по отдельности, а как семантические блоки (фильтры, слои, Residual-блоки).

## Ключевые особенности:
- **Групповая регуляризация**:
  - `level1`: Отдельные фильтры/нейроны
  - `block`: Архитектурные блоки (например, Residual-блоки в ResNet)
  - `layer`: Целые слои (Conv2d, Linear)
- **Гибкие комбинации норм**:
  ```python
  # Пример: L1 для фильтров + L2 для блоков
  config = [
      {"groups": ["level1"], "norm": "L1", "lambda": 0.01},
      {"groups": ["block"], "norm": "L2", "lambda": 0.001}
  ]
  ```
- **Автоматическое сжатие моделей**:
  - Удаляет неважные компоненты (обнуляет фильтры/блоки)
  - Сохраняет семантику архитектуры (не ломает структуру графа)

## Пример использования:
```python
from model import HierarchicalResNet, RegularizationCalculator

# Инициализация модели с группировкой параметров
model = HierarchicalResNet(num_blocks=[2, 2, 2, 2])

# Конфигурация регуляризации
config = [
    {"groups": ["block"], "norm": "L1", "lambda": 0.01},  # L1 для блоков
    {"groups": ["level1"], "norm": "L2", "lambda": 0.001} # L2 для фильтров
]

# Расчет потерь
regularizer = RegularizationCalculator(model)
loss = criterion(outputs, labels) + regularizer.compute_loss(config)
```

### Эффекты групповой регуляризации:
| Группа     | Тип нормы | Результат                          | Визуализация                     |
|------------|-----------|------------------------------------|----------------------------------|
| `level1`   | L1        | Разреженные фильтры                | ░ █ ░ ░ █ (активные фильтры)     |
| `block`    | L2        | Удаленные Residual-блоки           | [Block1] ░ [Block3] (Block2 ≈ 0) |
| `layer`    | L1+L2     | Упрощенные слои                    | Conv2d → ░ (веса слоя ≈ 0)       |

**Преимущества**:
1. **Интерпретируемость** — видно, какие блоки/фильтры важны.
2. **Сжатие моделей** — автоматическое удаление 30-70% параметров.
3. **Ускорение inference** — за счет обнуления целых компонентов.

подробнее о том как конфигурировать см отдельную документацию [group_loss/readme.md](./group_loss/readme.md)